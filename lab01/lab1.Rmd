---
title: "Quant II - Lab 1"
author: "Sylvan Zheng"
fig_caption: yes
output: pdf_document
editor_options: 
  chunk_output_type: inline
---


# The Science

## Setup
- Download the file `thescience.tsv` from this week's lab folder on GitHub 
- Move the file to a "lab 1" folder on your own computer
- Install the `tidyverse` and `here` R packages if you don't already have them

```{r message=F, warning=F}
knitr::opts_chunk$set(fig.width=4, fig.height=3)
# install.packages(c('tidyverse', 'here'))
library(tidyverse)
library(here)
df <- read_tsv(here('lab1/thescience.tsv'))
```

The data contains the following columns:

- **Potential Outcomes**: `y0` and `y1`
- **Observed Outcome**: `y`
- **Treatment**: `t`

```{r}
df %>% head
```

## Lab Demonstration:

- How does the observed outcome `y` relate to the treatment `t` and the potential outcomes `y0` and `y1`? 

```{r}
df %>% select(y0, y1, t, y) %>% tail
```

- Calculate the difference in means between the treated and the untreated. 
```{r}
mean(filter(df, t == 1)$y) - mean(filter(df, t == 0)$y)
```

- Calculate the true global average treatment effect 
```{r}
mean(df$y1 - df$y0)
```

- Explain why they are different. Show this using R.
```{r}
# Selection bias because there is a difference in the potential outcomes
# of the treatment vs. control
mean(filter(df, t == 1)$y0) - mean(filter(df, t == 0)$y0)

# We can see this graphically by plotting the data
df %>% ggplot(aes(x =t , y = y0)) + geom_point()

# Or we can observe this by noting that treatment and potential outcomes
# are correlated
cor(df$t, df$y0)
```

- What is the ATE vs the ATC and ATT? How would we calculate these from the science?

```{r}
# ATE (Average treatment effect - for everyone)
mean(df$y1 - df$y0)
## Same thing with fancy code
with(df, mean(y1) - mean(y0))

# ATC (Average treatment on control)
mean(filter(df, t==0)$y1 - filter(df, t==0)$y0)
with(filter(df, t==0), mean(y1) - mean(y0))

# ATT (Average treatment on treated)
mean(filter(df, t==1)$y1 - filter(df, t==1)$y0)
with(filter(df, t==1), mean(y1) - mean(y0))
```

# In-Lab Assignment

Do the next part in pairs. Prepare your work using RMarkdown. 

## Fixing the ATE estimation

- You get to play omnipotent being! Create an alternate universe (ie, a new treatment assignment and new outcome variable) such that the difference in means between the treated and the untreated can be reliably estimated.
- Estimate the difference in means and compare it to the true effect.
- Are they different? Why/How? 

```{r}
# Assign a random treatment
df$treat <- runif(nrow(df), 0, 1) > 0.5
df$outcome <- with(
  df,
  ifelse(treat, y1, y0)
)
# The difference in means is closer to 1 now
with(df, mean(y1-y0))
mean(filter(df, treat==1)$y0) - mean(filter(df, treat==0)$y0)

```


## Bias and Consistency of Estimators 

Consider the following estimator for the population mean:
```{r}
my.estimator <- function(data) {
  data[[1]] + 5 / length(data)
}

N <- 5

mu <- 0
sigma <- 1

some.data <- rnorm(N, mu, sigma)
some.data
my.estimator(some.data)

some.data <- rnorm(N, mu, sigma)
my.estimator(some.data)

some.data <- rnorm(N, mu, sigma)
my.estimator(some.data)
```

Is this estimator *biased*?

```{r}
estimates <- c()
for(i in 1:1000) {
  some.data <- rnorm(N, mu, sigma)
  e <- my.estimator(some.data)
  estimates <- c(estimates, e)
}
hist(estimates)
mean(estimates)
```

Is this estimator *consistent*?

```{r}
N <- 100000
estimates <- c()
for(i in 1:1000) {
  some.data <- rnorm(N, mu, sigma)
  e <- my.estimator(some.data)
  estimates <- c(estimates, e)
}
hist(estimates)
mean(estimates)
```

Is this estimator *asymptotically biased*?
How would we modify the above code to determine this?

## in-lab section

Now compare for the following estimator:

```{r}
my.estimator.2 <- function(data) {
  mean(data)
}
```

Write a function that pulls 1000 draws of samples of size N
from a normal distribution with mean `mu` and sd `sigma`
and estimates the population mean using the above estimator (my.estimator.2).

https://nyu.zoom.us/j/7610081729

Show a histogram or density plot for a few different values of N.
Do the results suggest consistency? Unbiasedness? Asymptotic unbiasedness?

```{r}
get_estimates <- function(N) {
  estimates <- c()
  for(i in 1:1000) {
    some.data <- rnorm(N, mu, sigma)
    e <- my.estimator.2(some.data)
    estimates <- c(estimates, e)
  }
  estimates
}

hist(get_estimates(10))
hist(get_estimates(100))
hist(get_estimates(1000))
```